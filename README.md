# Принцип работы train.py
  В самом начале считывается строка с аргументами. Этим занимается функция ger_args(). Она возвращает путь до файла считывания,
путь до папки для сохранения файла модели текста model.txt, нужно или не нужно приводить символы к нижнему регистру, а также запросил ли
пользователь справку. Обязательным является лишь путь до папки для model.txt. Остальные значения по умолчанию заданы как: 
считывание через консоль, к нижнему регистру приводить не нужно, инструкция не запрошена.
Если запрошена инструкция, на экран выводится инструкция и весь ввод данных повторяется.
Если считывание идёт через консоль, то закончить ввод нужно символами '///'.

  Дальше инициализируются генераторы: lines = line_generator(<путь до файла считывания>) - Подгружает по одной строке из файла(консоли);
tokens = token_generator(lines, <Приводить ли к нижнему регистру>) - Разделяет полученную строку на слова и возвращает их, приводя, если
необходимо, к нижнему регистру; bigrams = bigram_generator(tokens) - Возвращает пары подряд идущих слов, причём используется служебный
символ '&', который обозначает начало предложения. Т.е пара (pp, 'word'), где вместо pp может быть '?', '!', '.' или любая их комбинация, возвращается как ('&', 'word'). Причём пара ('word', pp) вернётся без изменений. Считается, что перед самым первым словом теста стоит '&'.

  Дальше идёт подсчёт количества повторений в тексте каждого слова и биграммы в функции count_words_and_pairs(bigrams).
  
  Далее идёт построение модели. Для каждого слова 'A' составляется список пар (следующее_слово 'B', вероятность его появления P), где вероятность P рассчитывается по формуле количество_пар('A', 'B')/количество_слов('A'). Причём вероятность хранится в виде рац. дроби.
  
  Далее эта модель сохраняется в файл model.txt в указанной пользователем директории в следующем формате:
<слово1> <след.слово1> <его вероятность> <след.слово2> <его вероятность> ... <след.словоN> <его вероятность> \n
... \n
<словоM> <след.слово1> <его вероятность> <след.слово2> <его вероятность> ... <след.словоK> <его вероятность>

  На этом работа программы завершается.
  
  # Принцип работы generate.py
  
  Сначала осуществляется ввод аргументов аналогично train.py. Различие лишь в самих аргументах: путь до папки с моделью model.txt,
первое слово сгенерированного текста, длина текста, путь до файла, в который идёт сохранение созданного текста, требуется ли справка.
Обязателен только первый параметр. Остальные по умолчанию соответственно:  '', 200, вывод в консоль, нет.
  Если запрошена инструкция, на экран выводится инструкция и весь ввод данных повторяется.
  
  Из файла model.txt идёт считывание данных. modelWords[key][i] и modelProbabilities[key][i] хранят i-ое слово из списка следующих
для слова key и его вероятность соответственно.
  
  Дальше идёт генерация текста и его вывод в файл(консоль). При каждом выводе идёт проверка, задан ли файл для сохранения 
(outputFile ==? ''), и по результатам проверки выводится или в файл, или в консоль. Если первое слово не задано пользователем, оно выбирается случайно из всех пар, где первый символ - символ окончания предложения: ('&', smth) - где вероятность следующего слова smth равна вероятности данной пары. Выводится первое слово (созданное пользо
вателем или сгенерированное), и если оно введено пользователем, выполняется проверка на его наличие в списке слов из model. Если его нет
в этом списке, то оно принимается равным '&'.

Дальше генерируется вся остальная последовательность. Очередное слово выбирается из всех пар, где на первой позиции стоит последнее написанное слово (prevWord, smth) по правилам, аналогичным генерации первого слова. Если новое слово - знак препинания, перед ним не ставится пробел. Это слово выводится с или без пробела. Если это знак препинания, означающий конец предложения, последнее слово принимается равным '&'. Иначе выведенному слову. Всего проходит столько итераций, сколько пользователь заросил при вводе длины текста (если не запросил, то 200).

  На этом работа программы завершается.
